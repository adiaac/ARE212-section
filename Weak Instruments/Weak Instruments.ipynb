{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79e28e5",
   "metadata": {},
   "source": [
    "# Weak instruments\n",
    "\n",
    "We've all heard that the rule of thumb for strong instruments is $F > 10$ (though troubling [recent work](https://arxiv.org/pdf/2010.05058.pdf) suggests that F might need to be much, much larger...). Let's explore in code the weak instruments problem, by examining the bias and precision of IV estimates in the just-identified case.\n",
    "\n",
    "First, we need to specify data-generating processes. Taking notation from the problem set, we want to set up a system that looks like:\n",
    "\n",
    "$$y = \\alpha + \\beta x + e$$\n",
    "\n",
    "$$x = Z\\pi + u$$\n",
    "\n",
    "where $x$ is a scalar variable and $Z$ is $N\\times l$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae109053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats.distributions as iid\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dbcc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP: y, x\n",
    "def dgp(N, beta, pi):\n",
    "    '''\n",
    "    Data-generating process\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    N (int) number of obervations\n",
    "    beta (float) true parameter\n",
    "    pi (lx1 np.array) tur first stage parameter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y (Nx1 np.array)\n",
    "    x (Nx1 np.array)\n",
    "    Z (Nxl np.array)\n",
    "    '''\n",
    "    # infer number of instruments from the size of pi\n",
    "    l = pi.shape[0]\n",
    "    # first generate Z\n",
    "    Z = scipy.stats.multivariate_normal(np.zeros(l), np.eye(l)).rvs(size=N)\n",
    "    if len(Z.shape) == 1:\n",
    "        Z = Z.reshape(-1,1)\n",
    "    \n",
    "    # now build X\n",
    "    X = Z@pi + iid.norm().rvs(size=(N,1))\n",
    "\n",
    "    # finally, build y\n",
    "    y = X*beta + iid.norm().rvs(size=(N,1))\n",
    "    \n",
    "    return y, X, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57fe327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "N = 5\n",
    "beta = 2\n",
    "pi = \n",
    "dgp(N, beta, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test IV regression\n",
    "N = 100\n",
    "beta = 2\n",
    "\n",
    "for p in [0.00001, 0.001, 0.1, 1, 500]:\n",
    "    # set pi\n",
    "    pi = np.array([[p]])\n",
    "    # generate data\n",
    "    y, X, Z = dgp(N, beta, pi)\n",
    "    # estimate beta via IV\n",
    "    bhat = np.linalg.solve(Z.T@X, Z.T@y) \n",
    "    # report\n",
    "    print(f'beta_hat for pi = {p}: {bhat.item():.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1101f4",
   "metadata": {},
   "source": [
    "### Check your understanding\n",
    "1. If I estimate beta via OLS given this DGP will it be biased? Why or why not?\n",
    "2. Why don't I need an intercept in these regressions?\n",
    "\n",
    "Let's write a two-stage least squares function to do this systematically. We want to do 2SLS because in the future we may want more instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sls(y, X, Z):\n",
    "    '''\n",
    "    Estimate 2 stage least squares given data on y, X and Z.\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    y (Nx1 np.array)\n",
    "    X (Nx1 np.array)\n",
    "    Z (Nxl np.array)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    beta_hat\n",
    "    '''\n",
    "    xhat = X@np.linalg.solve(Z.T@Z, Z.T@X)\n",
    "    beta_hat = np.linalg.solve(xhat.T@xhat, xhat.T@y)\n",
    "    return beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58079b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "y, X, Z = dgp(1000, 1, np.array([[1]]))\n",
    "two_sls(y, X, Z) # looks close!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be518a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapping everything up in one function\n",
    "def monteCarlo(N, beta, pi):\n",
    "    y, X, Z = dgp(N, beta, pi)\n",
    "    return two_sls(y, X, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056181bc",
   "metadata": {},
   "source": [
    "## Iterating\n",
    "\n",
    "Now that we have a DGP, let's set up a Monte Carlo simulation to see how it performs. First, we'll choose specific values for $\\beta$ and $\\pi$, say $\\beta=\\pi=1$. Let's first say we want to compare 3 dataset sizes: N=100, N=1000, and N=10000. For each, we want to plot the distribution of the IV estimator. To do this, our code will look like:\n",
    "\n",
    "```\n",
    "for N in [100, 1000, 10000]:\n",
    "    for a bunch of times:\n",
    "        create data of size N\n",
    "        estimate IV using that data\n",
    "    plot histogram\n",
    "```\n",
    "\n",
    "## Two quick asides: plotting and listing\n",
    "\n",
    "### Plotting\n",
    "\n",
    "First, I want to get in the weeds a bit about using the plotting package in python, ``matplotlib``. We've used it a bunch but I haven't yet explained it. We can think of matplotlib graphs as being composed of 3 elements:\n",
    "1. The figure. This is a container that holds all the rest of the plot; it is the first thing we need to initialize.\n",
    "2. The axes. These contain regions for plotting; a figure can have one axis or many axes. \n",
    "3. The Artist. Everything else you see on the plot is part of the artist- the lines, points, grid, etc. \n",
    "\n",
    "My personal preferred method for starting a matplotlib plot is to instantiate the figure and axes together using the plt.subplots() syntax (you can use this for just 1 \"subplot\" too, so it's very general!\n",
    "\n",
    "```\n",
    "fig, ax = plt.subplots(nrows, ncolumns, ...other args...)\n",
    "```\n",
    "\n",
    "with this syntax, I've named the figure ``fig`` and the axes ``ax``. In the case of multiple subplots, this axes is iterable and subsettable, so ``ax[0]`` is the first plotting region, and ``ax[1]`` is the second, and so forth. Let's see a simple example with two trivial plots before applying this to our objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make two histograms\n",
    "data1 = iid.norm().rvs(size=100)\n",
    "data2 = iid.norm(loc=10).rvs(size=100)\n",
    "\n",
    "# initialize figure, axes\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "# plot in first region\n",
    "ax[0].hist(data1)\n",
    "# plot in 2nd region\n",
    "ax[1].hist(data2)\n",
    "\n",
    "# add subtitles\n",
    "ax[0].set_title(\"Mean 0 data\")\n",
    "ax[1].set_title(\"Mean 10 data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765423d2",
   "metadata": {},
   "source": [
    "### List comprehension\n",
    "\n",
    "List comprehension is a computationally-fast way of creating lists \"on the fly\" in python. There is a whole notebook going over these in the [https://github.com/lghackett/ARE-comp-resources/tree/master/topics](ARE computational tools repository), but we'll do the quick version here.\n",
    "\n",
    "Let's say you want to make a list that goes from 0 to 100. You could do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d01576",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = []\n",
    "for i in range(100):\n",
    "    mylist.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aa6f5b",
   "metadata": {},
   "source": [
    "But for-loops aren't particularly nice in the sense that they are not the most compuatationally efficient, and tacking on another element to the list in each iteration also seems clunky. A list comprehension syntax does this for you like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3612c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = [i for i in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddde40f",
   "metadata": {},
   "source": [
    "Notice how the iteration is reproduced inside the square brackets, implying that a list is being produced.  You can do much more complicated things with list comprehension, including incorporating if-then statements, or adding functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0147ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of squares\n",
    "mylist = [i**2 for i in range(5)]\n",
    "print(mylist)\n",
    "\n",
    "# list only even numbers\n",
    "[x for x in range(9) if x % 2 == 0]\n",
    "\n",
    "# \"list\" comprehending a dictionary\n",
    "values = [1, 2, 3]\n",
    "mydict = {'Value number '+str(i) : values[i] for i in range(len(values))}\n",
    "print(mydict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d631cc",
   "metadata": {},
   "source": [
    "We'll try and stick to the simplest versions in our code, so for our purposes doing things in a list comprehension is faster than using a for-loop to iterate. So instead of doing:\n",
    "\n",
    "```\n",
    "betas = []\n",
    "for n in SampleSize:\n",
    "    beta = calculateIV\n",
    "    betas.append(beta)\n",
    "```\n",
    "\n",
    "we want:\n",
    "\n",
    "```\n",
    "betas = [calculateIV for n in sampleSize]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f257c04",
   "metadata": {},
   "source": [
    "## Coming back...\n",
    "\n",
    "Now back to our task. We will want to initialize 3 subplots, one for each N. I'll use a ``counter`` that I add 1 to in each iteration to move along these axes as we do our calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 # first axis starts at 0\n",
    "fig, ax = plt.subplots(1, 3) # initialize 3 subplots\n",
    "\n",
    "# set global parameters for DGP\n",
    "beta = 1\n",
    "pi = np.array([[1]])\n",
    "\n",
    "for N in [100, 1000, 10000]:\n",
    "    # calculate IV a bunch of times\n",
    "    beta_hats = [monteCarlo(N, beta, pi).item() for i in range(1000)]\n",
    "    # plot\n",
    "    ax[counter].hist(beta_hats)\n",
    "    ax[counter].set_title(f\"N = {N}\")\n",
    "    ax[counter].axvline(x=1, color='r', label='True beta')\n",
    "\n",
    "    # advance counter\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f1dc8",
   "metadata": {},
   "source": [
    "# Actually weak instruments\n",
    "Now let's iterate over $\\pi$ instead of N, seeing how we do with varyingly weak instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 # first axis starts at 0\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,7)) # initialize 3 subplots\n",
    "\n",
    "# set global parameters for DGP\n",
    "beta = 1\n",
    "N = 1000\n",
    "\n",
    "# start empty list to save to\n",
    "beta_hats = []\n",
    "\n",
    "for p in [0.001, 0.01, 0.1, 1]:\n",
    "    # calculate IV a bunch of times\n",
    "    beta_hats = np.array([monteCarlo(N, beta, np.array([[p]])).item() for i in range(1000)])\n",
    "    # some stats\n",
    "    minbeta = beta_hats.min()\n",
    "    maxbeta = beta_hats.max()\n",
    "    # plot\n",
    "    ax[counter].hist(beta_hats)\n",
    "    ax[counter].set_title(f\"pi = {p}; beta \\in [{minbeta:.1}, {maxbeta:.1}]\")\n",
    "    ax[counter].axvline(x=1, color='r', label='True beta')\n",
    "\n",
    "    # advance counter\n",
    "    counter = counter + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
